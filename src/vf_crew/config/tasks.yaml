data_preparation_task:
  description: >
    Load and prepare the time series data from the Excel file at: {file_path}

    Steps to perform:
    1. Use ExcelParserTool to read and parse the Excel file
    2. Use SelectTopSKUsTool to filter top {top_n_skus} SKUs by total volume
       - Calculate total volume per SKU across all weeks
       - Select top N SKUs with highest volumes
       - Keep track of selection summary
    3. Use DataValidationTool to validate data quality and identify problematic time series
       - Flag series with less than {min_weeks} weeks of data
       - Identify series with data quality issues
    4. Use TimeSeriesPreparationTool to format valid time series for Prophet modeling
       - Convert to Prophet format (ds, y columns)
       - Ensure proper date formatting

    You should process the top {top_n_skus} SKUs selected by volume. Keep track of:
    - Total time series found in file
    - Top N SKUs selected
    - Valid time series prepared
    - Invalid/flagged time series with reasons

  expected_output: >
    A JSON structure containing file paths and summaries (NOT the full data):
    {
      "prepared_series_file": "path to pickled file with Prophet-ready time series for top N SKUs",
      "invalid_series": [ list of flagged series with reasons (summary only, not full data) ],
      "selection_summary": { info about top N selection },
      "summary": {
        "total_time_series": number,
        "top_n_selected": number,
        "valid_count": number,
        "invalid_count": number,
        "validation_summary": { detailed stats }
      }
    }

    IMPORTANT: Do NOT include the full time series data in the output. Only include file paths and summary statistics.
    The tools will save data to temporary files and return file paths.

  agent: data_management_agent

validation_with_split_task:
  description: >
    Perform validation using train-test split on the prepared top N SKU time series data.

    Use the prepared_series_file path from the data_preparation_task output.

    Steps:
    1. Use TrainTestSplitTool with data_file (from data_preparation_task) to split data (80% train, 20% test)
       - Returns train_data_file and test_data_file paths
    2. Use ProphetModelTool with train_data_file to train Prophet on training data only
       - Returns forecast_file path containing forecasts for training period
    3. Use MetricsCalculatorTool with test_data_file and forecast_file to calculate validation metrics:
       - MAE (Mean Absolute Error)
       - RMSE (Root Mean Squared Error)
       - MAPE (Mean Absolute Percentage Error)
       - RÂ² (Coefficient of Determination)
       - Forecast Bias
       - Returns metrics_results list and summary_stats

    Process all selected top N SKUs and collect validation metrics for each.
    Create a summary of validation performance across all selected series.

    IMPORTANT: All tools use file-based data passing. Pass file paths between tools, not raw data.

    NOTE: This validation is for assessment only. The final forecast will use the full dataset.

  expected_output: >
    A JSON structure containing validation results (NOT file paths for metrics, but the actual summary):
    {
      "metrics_results": [
        {
          "ts_key": "...",
          "sku_name": "...",
          "status": "success",
          "metrics": {
            "MAE": number,
            "RMSE": number,
            "MAPE": number,
            "R2": number,
            "Bias": number,
            "n_samples": number
          }
        },
        ...
      ],
      "summary_stats": {
        "avg_MAE": number,
        "avg_RMSE": number,
        "avg_MAPE": number,
        "avg_R2": number,
        "total_series": number,
        "successful_series": number,
        "failed_series": number
      }
    }

  agent: validation_agent
  context:
    - data_preparation_task

final_forecast_generation_task:
  description: >
    Generate final 6-month forecasts using the FULL dataset (no split) for the top N selected SKUs.

    For EACH valid time series from the selected top N SKUs:
    1. Use ProphetModelTool to train on the FULL dataset (all {n_weeks} weeks)
    2. Generate forecasts for {forecast_periods} periods ahead (6 months = 26 weeks)
    3. Collect forecasts with confidence intervals (yhat, yhat_lower, yhat_upper)

    Process ALL selected top N SKUs and compile all forecasts with metadata.
    Track any failures or errors during forecasting.

  expected_output: >
    A JSON structure containing file path and summary:
    {
      "forecasts_file": "path to pickled file containing all forecast data",
      "forecast_summary": [
        {
          "time_series_key": "...",
          "sku_name": "...",
          "forecast_periods": number
        }
      ],
      "summary": {
        "total_forecasts_generated": number,
        "failed_forecasts": number,
        "forecast_horizon_weeks": 26
      }
    }

    IMPORTANT: Do NOT include the full forecast DataFrames in the output. Save to file and return the file path only.

  agent: ml_forecasting_agent
  context:
    - data_preparation_task

results_export_task:
  description: >
    Export all results to Excel with visualizations for the top N selected SKUs.

    Use ExcelExportTool with the following inputs:
    1. forecasts_file: File path from final_forecast_generation_task output (contains all forecast data)
    2. validation_results: The validation_with_split_task output dict (contains metrics_results and summary_stats)
    3. data_prep_results: The data_preparation_task output dict (contains invalid_series list)
    4. output_path: {output_path}

    The ExcelExportTool will:
    - Load forecast data from forecasts_file pickle
    - Extract metrics from validation_results dict
    - Extract invalid_series from data_prep_results dict
    - Create professional Excel workbook with multiple sheets:
      * Sheet 1: Future forecasts for top N SKUs with product dimensions
      * Sheet 2: Validation metrics summary for top N SKUs
      * Sheet 3: Flagged/skipped time series log
      * Sheet 4: Overall summary, statistics, and top N selection details

    IMPORTANT: Pass the forecasts_file PATH (not the data itself), and pass the validation_results
    and data_prep_results DICTS (not file paths) to ExcelExportTool.

    Optional: Use VisualizationTool to create sample charts for top products.
    - VisualizationTool requires: historical_data_file, forecast_data_file, time_series_key, title

    Save the Excel file to: {output_path}

  expected_output: >
    A completion message with:
    - Output file path (absolute path to the Excel file)
    - Number of forecasts exported
    - Number of validation metrics exported
    - Number of flagged series logged
    - List of sheets created
    - File size information (in MB)

  agent: validation_agent
  context:
    - data_preparation_task
    - validation_with_split_task
    - final_forecast_generation_task
